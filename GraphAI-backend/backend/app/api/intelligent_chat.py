"""
æ™ºèƒ½å¯¹è¯API

æä¾›æ–‡æ¡£å…¥åº“æµç¨‹å’Œæ£€ç´¢ç”Ÿæˆæµç¨‹çš„åˆ†æ­¥æ‰§è¡ŒAPI
"""
from fastapi import APIRouter, HTTPException, Query, Depends
from fastapi.responses import StreamingResponse
from typing import Optional, List, Dict, Any
from pydantic import BaseModel
from app.core.mysql_client import SessionLocal, get_db
from sqlalchemy.orm import Session
from app.models.document_upload import DocumentUpload
from app.models.user import User
from app.core.auth import get_current_user_optional
import logging
import json

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/intelligent-chat", tags=["æ™ºèƒ½å¯¹è¯"])


# ==================== è¯·æ±‚æ¨¡å‹ ====================

class PreviewTemplateRequest(BaseModel):
    """é¢„è§ˆLLMç”Ÿæˆçš„å®ä½“å…³ç³»æ¨¡æ¿è¯·æ±‚"""
    upload_id: int
    provider: str = "qianwen"
    temperature: float = 0.7
    system_prompt: Optional[str] = None  # è‡ªå®šä¹‰System Promptï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä½¿ç”¨é»˜è®¤ï¼‰
    user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰User Promptæ¨¡æ¿ï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™ä½¿ç”¨é»˜è®¤ï¼‰
    parse_mode: str = "summary_parse"  # è§£ææ¨¡å¼ï¼š"summary_parse"ï¼ˆæ‘˜è¦è§£æï¼‰æˆ– "full_parse"ï¼ˆå…¨æ–‡è§£æï¼‰


class Step1GraphitiEpisodeRequest(BaseModel):
    upload_id: int
    provider: str = "qianwen"
    temperature: float = 0.7
    # æ¨¡æ¿é…ç½®ï¼ˆå¿…é€‰ï¼‰
    template_mode: str  # "llm_generate" æˆ– "json_config"ï¼ˆå¿…é€‰ï¼Œæ— é»˜è®¤å€¼ï¼‰
    template_config_json: Optional[Dict[str, Any]] = None  # JSONé…ç½®ï¼ˆjson_config æ¨¡å¼æ—¶å¿…å¡«ï¼‰
    episode_body: Optional[str] = None  # ç”¨æˆ·è‡ªå®šä¹‰çš„ Episode bodyï¼ˆå¯é€‰ï¼‰
    parse_mode: str = "summary_parse"  # è§£ææ¨¡å¼ï¼š"summary_parse"ï¼ˆæ‘˜è¦è§£æï¼‰æˆ– "full_parse"ï¼ˆå…¨æ–‡è§£æï¼‰
    system_prompt: Optional[str] = None  # è‡ªå®šä¹‰System Promptï¼ˆLLMç”Ÿæˆæ¨¡å¼ï¼‰
    user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰User Promptæ¨¡æ¿ï¼ˆLLMç”Ÿæˆæ¨¡å¼ï¼‰


class CognifyTemplatePreviewRequest(BaseModel):
    """Cognify æ¨¡æ¿é¢„è§ˆç”Ÿæˆè¯·æ±‚"""
    upload_id: int
    system_prompt: Optional[str] = None  # è‡ªå®šä¹‰ System Promptï¼ˆå¯é€‰ï¼‰
    user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰ User Prompt æ¨¡æ¿ï¼ˆå¯é€‰ï¼‰
    template_type: str = "default"  # æ¨¡ç‰ˆç±»å‹ï¼ˆæš‚æ—¶åªæœ‰ defaultï¼‰
    provider: str = "qianwen"  # LLMæä¾›å•†ï¼šqianwen, deepseek, kimi, glm


class MemifyPromptPreviewRequest(BaseModel):
    """Memifyæç¤ºè¯é¢„è§ˆè¯·æ±‚"""
    upload_id: int
    system_prompt: Optional[str] = None  # è‡ªå®šä¹‰ System Promptï¼ˆå¯é€‰ï¼‰
    user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰ User Prompt æ¨¡æ¿ï¼ˆå¯é€‰ï¼Œæ”¯æŒå ä½ç¬¦ï¼š{document_name}, {chat}, {rules}ç­‰ï¼‰
    template_type: str = "default"  # æ¨¡ç‰ˆç±»å‹ï¼ˆæš‚æ—¶åªæœ‰ defaultï¼‰


class MemifyRulesPreviewRequest(BaseModel):
    """Memifyè§„åˆ™åˆ—è¡¨é¢„è§ˆç”Ÿæˆè¯·æ±‚"""
    upload_id: int
    system_prompt: Optional[str] = None  # è‡ªå®šä¹‰ System Promptï¼ˆå¯é€‰ï¼‰
    user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰ User Prompt æ¨¡æ¿ï¼ˆå¯é€‰ï¼Œæ”¯æŒå ä½ç¬¦ï¼š{document_name}, {section_title}, {section_content}ç­‰ï¼‰
    template_type: str = "default"  # æ¨¡ç‰ˆç±»å‹ï¼ˆæš‚æ—¶åªæœ‰ defaultï¼‰
    provider: str = "qianwen"  # LLMæä¾›å•†ï¼šqianwen, deepseek, kimi, glm


class Step2CogneeBuildRequest(BaseModel):
    upload_id: int
    group_id: Optional[str] = None  # å¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨ç”Ÿæˆ
    provider: str = "local"
    temperature: Optional[float] = 0.7  # LLM æ¸©åº¦å‚æ•°
    # æ¨¡æ¿é…ç½®ï¼ˆcognifyé˜¶æ®µï¼‰
    cognify_template_mode: str = "llm_generate"  # "llm_generate" æˆ– "json_config"
    cognify_template_config_json: Optional[Dict[str, Any]] = None  # JSONé…ç½®ï¼ˆentity_types, edge_types, edge_type_mapï¼‰
    cognify_system_prompt: Optional[str] = None  # è‡ªå®šä¹‰ System Promptï¼ˆLLMç”Ÿæˆæ¨¡å¼æ—¶ä½¿ç”¨ï¼‰
    cognify_user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰ User Prompt æ¨¡æ¿ï¼ˆLLMç”Ÿæˆæ¨¡å¼æ—¶ä½¿ç”¨ï¼‰
    cognify_template_type: str = "default"  # æ¨¡ç‰ˆç±»å‹
    # æ¨¡æ¿é…ç½®ï¼ˆmemifyé˜¶æ®µï¼‰
    memify_template_mode: str = "llm_generate"  # "llm_generate" æˆ– "json_config"
    memify_template_config_json: Optional[Dict[str, Any]] = None  # JSONé…ç½®ï¼ˆextractionå’Œenrichmenté…ç½®ï¼‰
    memify_system_prompt: Optional[str] = None  # è‡ªå®šä¹‰ System Promptï¼ˆLLMç”Ÿæˆæ¨¡å¼æ—¶ä½¿ç”¨ï¼Œç”¨äºenrichmentä»»åŠ¡ï¼‰
    memify_user_prompt_template: Optional[str] = None  # è‡ªå®šä¹‰ User Prompt æ¨¡æ¿ï¼ˆLLMç”Ÿæˆæ¨¡å¼æ—¶ä½¿ç”¨ï¼Œç”¨äºenrichmentä»»åŠ¡ï¼‰
    memify_template_type: str = "default"  # æ¨¡ç‰ˆç±»å‹ï¼ˆæš‚æ—¶åªæœ‰ defaultï¼‰
    memify_rules: Optional[List[str]] = None  # LLMç”Ÿæˆæ¨¡å¼ä¸‹ï¼Œå‰ç«¯å·²ç”Ÿæˆçš„è§„åˆ™åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰


class Step3MilvusVectorizeRequest(BaseModel):
    upload_id: int
    group_id: str


class Step4MilvusRecallRequest(BaseModel):
    query: str
    top_k: int = 50
    group_ids: Optional[List[str]] = None


class Step5Neo4jRefineRequest(BaseModel):
    query: str
    recall_results: List[Dict[str, Any]]


class Step6Mem0InjectRequest(BaseModel):
    query: str
    refined_results: List[Dict[str, Any]]
    user_id: Optional[str] = None
    session_id: Optional[str] = None


class Step7LLMGenerateRequest(BaseModel):
    query: str
    retrieval_results: Optional[List[Dict[str, Any]]] = None  # æ™ºèƒ½æ£€ç´¢ç»“æœï¼ˆv3.0æ ¼å¼ï¼‰
    provider: str = "local"
    temperature: float = 0.7


class Mem0ChatRequest(BaseModel):
    """Mem0 ç‹¬ç«‹é—®ç­”è¯·æ±‚"""
    query: str
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    conversation_history: Optional[List[Dict[str, Any]]] = None
    provider: str = "local"
    temperature: float = 0.7


class SmartRetrievalRequest(BaseModel):
    """æ™ºèƒ½æ£€ç´¢è¯·æ±‚"""
    query: str
    top_k: int = 50
    min_score: float = 70.0  # æ–°å¢ï¼šæœ€å°åˆ†æ•°é˜ˆå€¼ï¼ˆ0-100ï¼‰
    group_ids: Optional[List[str]] = None
    enable_refine: bool = True


# ==================== æ–‡æ¡£å…¥åº“æµç¨‹ API ====================

@router.post("/preview-template")
async def preview_template(
    request: PreviewTemplateRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    é¢„è§ˆLLMç”Ÿæˆçš„å®ä½“å…³ç³»æ¨¡æ¿ï¼ˆä¸æ‰§è¡ŒGraphitiï¼‰
    
    ç”¨äºåœ¨æ‰§è¡Œå‰æ˜¾ç¤ºå’Œç¼–è¾‘ entity_typesã€edge_typesã€edge_type_map
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è§£æ
        if not document.parsed_content_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªè§£æï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£è§£æ")
        
        service = IntelligentChatService()
        result = await service.preview_graphiti_template(
            db=db,
            upload_id=request.upload_id,
            provider=request.provider,
            temperature=request.temperature,
            system_prompt=request.system_prompt,
            user_prompt_template=request.user_prompt_template,
            parse_mode=request.parse_mode
        )
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆæ¨¡æ¿ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆå¤±è´¥: {str(e)}")


@router.get("/preview-episode-body/{upload_id}")
async def preview_episode_body(
    upload_id: int,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    é¢„è§ˆ Episode body å†…å®¹ï¼ˆä¸æ‰§è¡Œå¤„ç†ï¼‰
    
    ç”¨äºåœ¨æ‰§è¡Œå‰æ˜¾ç¤ºå’Œç¼–è¾‘ Episode body
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è§£æ
        if not document.parsed_content_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªè§£æï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£è§£æ")
        
        service = IntelligentChatService()
        result = await service.preview_episode_body(upload_id)
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆ Episode body å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆå¤±è´¥: {str(e)}")


@router.post("/step1/graphiti-episode")
async def step1_graphiti_episode(
    request: Step1GraphitiEpisodeRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤1: Graphitiæ–‡æ¡£çº§å¤„ç†
    
    åˆ›å»ºæ–‡æ¡£çº§Episodeï¼Œæå–Entityå’ŒEdge
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²è§£æ
        if not document.parsed_content_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªè§£æï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£è§£æ")
        
        # éªŒè¯ template_mode
        if request.template_mode not in ["llm_generate", "json_config"]:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„ template_mode: {request.template_mode}ï¼Œåªæ”¯æŒ 'llm_generate' æˆ– 'json_config'"
            )
        
        # éªŒè¯ json_config æ¨¡å¼å¿…é¡»æä¾› template_config_json
        if request.template_mode == "json_config" and not request.template_config_json:
            raise HTTPException(
                status_code=400,
                detail="json_config æ¨¡å¼å¿…é¡»æä¾› template_config_json å‚æ•°"
            )
        
        service = IntelligentChatService()
        result = await service.step1_graphiti_episode(
            upload_id=request.upload_id,
            provider=request.provider,
            temperature=request.temperature,
            template_mode=request.template_mode,
            template_config_json=request.template_config_json,
            episode_body=request.episode_body,
            parse_mode=request.parse_mode,
            system_prompt=request.system_prompt,
            user_prompt_template=request.user_prompt_template
        )
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ­¥éª¤1æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.get("/graphiti-result/{upload_id}")
async def get_graphiti_result(
    upload_id: int,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    è·å– Graphiti æ‰§è¡Œç»“æœæ‘˜è¦
    
    ä» Neo4j æŸ¥è¯¢ Episode ä¿¡æ¯ï¼Œç»Ÿè®¡å®ä½“å’Œå…³ç³»æ•°é‡ï¼Œä» MySQL æŸ¥è¯¢æ–‡æ¡£ä¿¡æ¯
    è¿”å›å®Œæ•´çš„æ‰§è¡Œç»“æœæ‘˜è¦
    """
    try:
        from app.core.neo4j_client import neo4j_client
        from app.core.utils import serialize_neo4j_properties
        
        # 1. ä» MySQL æŸ¥è¯¢æ–‡æ¡£ä¿¡æ¯
        document = db.query(DocumentUpload).filter(DocumentUpload.id == upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={upload_id}")
        
        # 2. è·å– group_idï¼ˆdocument_idï¼‰
        group_id = document.document_id
        if not group_id:
            # æ–‡æ¡£å°šæœªæ‰§è¡Œè¿‡ Graphiti
            return {
                "success": False,
                "message": "æ–‡æ¡£å°šæœªæ‰§è¡Œè¿‡ Graphiti",
                "upload_id": upload_id,
                "file_name": document.file_name,
                "upload_time": document.upload_time.isoformat() if document.upload_time else None
            }
        
        # 3. ä» Neo4j æŸ¥è¯¢ Episode ä¿¡æ¯
        episode_query = """
        MATCH (e:Episodic)
        WHERE e.group_id = $group_id
        RETURN e.uuid as episode_uuid, e.episode_id as episode_id, 
               e.doc_id as doc_id, e.version as version, e.episode_type as episode_type,
               e.created_at as created_at, properties(e) as properties
        ORDER BY e.created_at DESC
        LIMIT 1
        """
        
        episode_results = neo4j_client.execute_query(episode_query, {"group_id": group_id})
        
        if not episode_results or len(episode_results) == 0:
            # Episode ä¸å­˜åœ¨
            return {
                "success": False,
                "message": "Graphiti Episode ä¸å­˜åœ¨",
                "upload_id": upload_id,
                "group_id": group_id,
                "file_name": document.file_name,
                "upload_time": document.upload_time.isoformat() if document.upload_time else None
            }
        
        episode_data = episode_results[0]
        episode_uuid = episode_data.get("episode_uuid")
        episode_id = episode_data.get("episode_id")
        doc_id = episode_data.get("doc_id")
        version = episode_data.get("version")
        episode_type = episode_data.get("episode_type")
        
        # 4. ç»Ÿè®¡å®ä½“å’Œå…³ç³»æ•°é‡
        entity_count_query = """
        MATCH (n:Entity)
        WHERE n.group_id = $group_id
        RETURN count(n) as entity_count
        """
        
        edge_count_query = """
        MATCH ()-[r:RELATES_TO|MENTIONS|CONTAINS|HAS_MEMBER]->()
        WHERE r.group_id = $group_id
        RETURN count(r) as edge_count
        """
        
        entity_count_result = neo4j_client.execute_query(entity_count_query, {"group_id": group_id})
        edge_count_result = neo4j_client.execute_query(edge_count_query, {"group_id": group_id})
        
        entity_count = entity_count_result[0].get("entity_count", 0) if entity_count_result else 0
        edge_count = edge_count_result[0].get("edge_count", 0) if edge_count_result else 0
        
        # 5. ç»Ÿè®¡å®ä½“ç±»å‹å’Œå…³ç³»ç±»å‹æ•°é‡
        entity_type_query = """
        MATCH (n:Entity)
        WHERE n.group_id = $group_id
        UNWIND labels(n) as label
        WITH label
        WHERE label <> 'Entity'
        RETURN label, count(*) as count
        ORDER BY count DESC
        """
        
        edge_type_query = """
        MATCH ()-[r:RELATES_TO|MENTIONS|CONTAINS|HAS_MEMBER]->()
        WHERE r.group_id = $group_id
        RETURN type(r) as type, count(*) as count
        ORDER BY count DESC
        """
        
        entity_type_results = neo4j_client.execute_query(entity_type_query, {"group_id": group_id})
        edge_type_results = neo4j_client.execute_query(edge_type_query, {"group_id": group_id})
        
        entity_type_counts = {item.get("label"): item.get("count", 0) for item in entity_type_results} if entity_type_results else {}
        edge_type_counts = {item.get("type"): item.get("count", 0) for item in edge_type_results} if edge_type_results else {}
        
        # 6. è¿”å›å®Œæ•´çš„æ‰§è¡Œç»“æœæ‘˜è¦
        return {
            "success": True,
            "upload_id": upload_id,
            "file_name": document.file_name,
            "upload_time": document.upload_time.isoformat() if document.upload_time else None,
            "episode_uuid": episode_uuid,
            "episode_id": episode_id,
            "doc_id": doc_id,
            "group_id": group_id,
            "episode_type": episode_type,
            "version": version,
            "entity_count": entity_count,
            "edge_count": edge_count,
            "entity_type_counts": entity_type_counts,
            "edge_type_counts": edge_type_counts
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å– Graphiti æ‰§è¡Œç»“æœå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/cognify-template/preview")
async def preview_cognify_template(
    request: CognifyTemplatePreviewRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    é¢„è§ˆç”Ÿæˆ Cognify æ¨¡æ¿ JSON
    
    ä½¿ç”¨æ‰¹æ¬¡å¤„ç†æ–¹æ¡ˆï¼ŒåŸºäºæ‰€æœ‰ç« èŠ‚ç”Ÿæˆæ¨¡æ¿ï¼Œä¸å®é™…æ‰§è¡Œé€»è¾‘ä¸€è‡´
    """
    try:
        import json
        import os
        import asyncio
        from app.services.cognee_service import CogneeService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²åˆ†å—
        if not document.chunks_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªåˆ†å—ï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£åˆ†å—")
        
        # è¯»å–åˆ†å—å†…å®¹
        chunks_file_abs = os.path.join("/app", document.chunks_path) if not os.path.isabs(document.chunks_path) else document.chunks_path
        if not os.path.exists(chunks_file_abs):
            raise HTTPException(status_code=404, detail="åˆ†å—æ–‡ä»¶ä¸å­˜åœ¨")
        
        with open(chunks_file_abs, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        
        chunks = chunks_data.get("chunks", [])
        if not chunks:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£åˆ†å—ä¸ºç©º")
        
        # å‡†å¤‡ç« èŠ‚æ•°æ®ï¼ˆä¸å®é™…æ‰§è¡Œé€»è¾‘ä¸€è‡´ï¼‰
        section_texts = []
        section_metadata = []
        for idx, chunk in enumerate(chunks):
            section_title = chunk.get("title", f"ç« èŠ‚_{idx+1}")
            section_content = chunk.get("content", "")
            if not section_content.strip():
                continue
            section_texts.append(section_content)
            section_metadata.append({
                "title": section_title,
                "section_uuid": chunk.get("uuid"),
                "index": idx
            })
        
        if not section_texts:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æœ‰æ•ˆçš„ç« èŠ‚å†…å®¹")
        
        # ä½¿ç”¨ CogneeService çš„æ‰¹æ¬¡å¤„ç†é€»è¾‘
        cognee_service = CogneeService()
        provider = getattr(request, 'provider', 'qianwen')  # ä»è¯·æ±‚è·å– providerï¼Œé»˜è®¤ä¸º qianwen
        
        # 1. å°†ç« èŠ‚åˆ†ç»„
        batches = cognee_service._group_sections_by_token_limit(
            section_texts=section_texts,
            section_metadata=section_metadata,
            provider=provider
        )
        
        # 2. å¹¶è¡Œå¤„ç†æ‰¹æ¬¡ï¼ˆæœ€å¤§å¹¶å‘æ•°=3ï¼‰
        max_concurrent = 3
        semaphore = asyncio.Semaphore(max_concurrent)
        
        system_prompt = request.system_prompt
        user_prompt_template = request.user_prompt_template
        temperature = 0.3
        
        batch_tasks = [
            cognee_service._process_batch_template(
                batch=batch,
                batch_index=i+1,
                system_prompt=system_prompt,
                user_prompt_template=user_prompt_template,
                temperature=temperature,
                semaphore=semaphore,
                provider=provider
            )
            for i, batch in enumerate(batches)
        ]
        
        batch_results = await asyncio.gather(*batch_tasks)
        
        # 3. è¿‡æ»¤æ‰å¤±è´¥çš„ç»“æœ
        successful_results = [r for r in batch_results if r is not None]
        failed_count = len(batch_results) - len(successful_results)
        
        if failed_count > 0:
            logger.warning(f"âš ï¸ é¢„è§ˆæ—¶ {failed_count} ä¸ªæ‰¹æ¬¡å¤„ç†å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æˆåŠŸçš„ç»“æœ")
        
        if not successful_results:
            raise HTTPException(status_code=500, detail="æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆæ¨¡æ¿")
        
        # 4. åˆå¹¶æ‰¹æ¬¡ç»“æœ
        template_json = await cognee_service._merge_batch_templates(
            batch_results=successful_results,
            provider=provider
        )
        
        # è¿”å›é¢„è§ˆä¿¡æ¯
        return {
            "success": True,
            "template_json": template_json,
            "preview_info": {
                "total_sections": len(section_texts),
                "total_batches": len(batches),
                "successful_batches": len(successful_results),
                "failed_batches": failed_count
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆæ¨¡æ¿ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆæ¨¡æ¿ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/memify-rules/preview")
async def preview_memify_rules(
    request: MemifyRulesPreviewRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    é¢„è§ˆç”Ÿæˆ Memify è§„åˆ™åˆ—è¡¨
    
    ä½¿ç”¨æ‰¹æ¬¡å¤„ç†æ–¹æ¡ˆï¼ŒåŸºäºæ‰€æœ‰ç« èŠ‚ç”Ÿæˆè§„åˆ™åˆ—è¡¨ï¼Œä¸å®é™…æ‰§è¡Œé€»è¾‘ä¸€è‡´
    æ”¯æŒé•¿æ–‡æ¡£ï¼Œè‡ªåŠ¨åˆ†æ‰¹å¤„ç†ï¼Œä½¿ç”¨LLMç»Ÿä¸€æ ¼å¼
    """
    logger.info(f"ğŸ“¥ æ”¶åˆ°è§„åˆ™åˆ—è¡¨ç”Ÿæˆè¯·æ±‚: upload_id={request.upload_id}, template_type={request.template_type}")
    try:
        import json
        import os
        from app.services.cognee_service import CogneeService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²åˆ†å—
        if not document.chunks_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªåˆ†å—ï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£åˆ†å—")
        
        # è¯»å–åˆ†å—å†…å®¹
        chunks_file_abs = os.path.join("/app", document.chunks_path) if not os.path.isabs(document.chunks_path) else document.chunks_path
        if not os.path.exists(chunks_file_abs):
            raise HTTPException(status_code=404, detail="åˆ†å—æ–‡ä»¶ä¸å­˜åœ¨")
        
        with open(chunks_file_abs, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        
        chunks = chunks_data.get("chunks", [])
        if not chunks:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£åˆ†å—ä¸ºç©º")
        
        # å‡†å¤‡ç« èŠ‚æ•°æ®ï¼ˆä¸å®é™…æ‰§è¡Œé€»è¾‘ä¸€è‡´ï¼‰
        section_texts = []
        section_metadata = []
        for idx, chunk in enumerate(chunks):
            section_title = chunk.get("title", f"ç« èŠ‚_{idx+1}")
            section_content = chunk.get("content", "")
            if not section_content.strip():
                continue
            section_texts.append(section_content)
            section_metadata.append({
                "title": section_title,
                "section_uuid": chunk.get("uuid"),
                "index": idx
            })
        
        if not section_texts:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æœ‰æ•ˆçš„ç« èŠ‚å†…å®¹")
        
        # å‡†å¤‡æç¤ºè¯
        system_prompt = request.system_prompt
        user_prompt_template = request.user_prompt_template
        
        document_name = document.file_name or "æ–‡æ¡£"
        provider = getattr(request, 'provider', 'qianwen')  # ä»è¯·æ±‚è·å– providerï¼Œé»˜è®¤ä¸º qianwen
        max_concurrent = 3  # æœ€å¤§å¹¶å‘æ•°
        
        # ä½¿ç”¨ CogneeService çš„æ‰¹æ¬¡å¤„ç†é€»è¾‘
        cognee_service = CogneeService()
        rules = await cognee_service._generate_memify_rules_batch(
            section_texts=section_texts,
            section_metadata=section_metadata,
            document_name=document_name,
            system_prompt=system_prompt,
            user_prompt_template=user_prompt_template,
            provider=provider,
            max_concurrent=max_concurrent
        )
        
        logger.info(f"âœ… è§„åˆ™åˆ—è¡¨ç”ŸæˆæˆåŠŸï¼Œå…± {len(rules)} æ¡è§„åˆ™")
        for i, rule in enumerate(rules[:5], 1):  # åªè®°å½•å‰5æ¡
            logger.info(f"  è§„åˆ™ {i}: {rule[:100]}...")
        
        return {
            "success": True,
            "rules": rules,
            "rules_count": len(rules),
            "document_name": document_name
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆè§„åˆ™åˆ—è¡¨ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆè§„åˆ™åˆ—è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/memify-prompt/preview")
async def preview_memify_prompt(
    request: MemifyPromptPreviewRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    é¢„è§ˆ Memify å®Œæ•´æç¤ºè¯ï¼ˆæ›¿æ¢å ä½ç¬¦åï¼‰
    
    ç”¨äºåœ¨æ‰§è¡Œå‰é¢„è§ˆ enrichment ä»»åŠ¡çš„å®Œæ•´æç¤ºè¯
    """
    try:
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # è·å–æ–‡æ¡£åç§°
        document_name = document.file_name or "æ–‡æ¡£"
        
        # å‡†å¤‡å ä½ç¬¦æ•°æ®
        placeholder_data = {
            "document_name": document_name,
            "chat": "[ç¤ºä¾‹å¯¹è¯å†…å®¹ï¼šè¿™æ˜¯ä»æ–‡æ¡£ä¸­æå–çš„æ–‡æœ¬å†…å®¹ï¼Œç”¨äºç”Ÿæˆè§„åˆ™å…³è”]",
            "rules": "[ç¤ºä¾‹è§„åˆ™åˆ—è¡¨ï¼š\n- è§„åˆ™1ï¼šç¤ºä¾‹è§„åˆ™å†…å®¹\n- è§„åˆ™2ï¼šç¤ºä¾‹è§„åˆ™å†…å®¹]"
        }
        
        # è·å–é»˜è®¤æç¤ºè¯ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not request.system_prompt:
            # ä½¿ç”¨é»˜è®¤çš„System Prompt
            from cognee.infrastructure.llm.prompts import render_prompt
            try:
                default_system_prompt = render_prompt("coding_rule_association_agent_system.txt", context={})
            except Exception:
                default_system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§„åˆ™å…³è”ä¸“å®¶ï¼Œæ“…é•¿ä»å¯¹è¯å†…å®¹ä¸­æå–å’Œå…³è”ç¼–ç è§„åˆ™ã€‚"
        else:
            default_system_prompt = request.system_prompt
        
        if not request.user_prompt_template:
            # ä½¿ç”¨é»˜è®¤çš„User Prompt
            from cognee.infrastructure.llm.prompts import render_prompt
            try:
                default_user_prompt_template = render_prompt("coding_rule_association_agent_user.txt", context=placeholder_data)
            except Exception:
                default_user_prompt_template = f"""åˆ†æä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œæå–å¹¶å…³è”ç¼–ç è§„åˆ™ã€‚

å¯¹è¯å†…å®¹ï¼š
{{chat}}

ç°æœ‰è§„åˆ™ï¼š
{{rules}}

è¯·æå–ä¸å¯¹è¯å†…å®¹ç›¸å…³çš„ç¼–ç è§„åˆ™ã€‚"""
        else:
            # æ›¿æ¢å ä½ç¬¦
            default_user_prompt_template = request.user_prompt_template.replace("{document_name}", placeholder_data["document_name"])
            default_user_prompt_template = default_user_prompt_template.replace("{chat}", placeholder_data["chat"])
            default_user_prompt_template = default_user_prompt_template.replace("{rules}", placeholder_data["rules"])
        
        return {
            "success": True,
            "system_prompt": default_system_prompt,
            "user_prompt": default_user_prompt_template,
            "placeholder_data": placeholder_data,
            "message": "æç¤ºè¯é¢„è§ˆæˆåŠŸï¼ˆå ä½ç¬¦å·²æ›¿æ¢ä¸ºç¤ºä¾‹æ•°æ®ï¼‰"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„è§ˆMemifyæç¤ºè¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é¢„è§ˆå¤±è´¥: {str(e)}")


@router.delete("/cognee-graph/{upload_id}", response_model=Dict[str, Any])
async def delete_cognee_graph(
    upload_id: int,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    åˆ é™¤æ–‡æ¡£çš„Cogneeå›¾è°±æ•°æ®
    
    åˆ é™¤åŒ…æ‹¬ï¼š
    1. Neo4jä¸­çš„CogneeèŠ‚ç‚¹ï¼ˆTextDocumentã€DataNodeã€DocumentChunkã€Entityã€EntityTypeç­‰ï¼‰
    2. Milvusä¸­çš„å‘é‡æ•°æ®ï¼ˆç›¸å…³collectionï¼‰
    3. Cogneeå†…éƒ¨çš„datasetè®°å½•
    """
    try:
        from app.services.cognee_service import CogneeService
        
        # è·å–æ–‡æ¡£ä¿¡æ¯
        document = db.query(DocumentUpload).filter(DocumentUpload.id == upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={upload_id}")
        
        group_id = document.document_id
        if not group_id:
            raise HTTPException(status_code=400, detail=f"æ–‡æ¡£æœªå¤„ç†ï¼Œæ²¡æœ‰group_id: upload_id={upload_id}")
        
        logger.info(f"å¼€å§‹åˆ é™¤Cogneeå›¾è°±: upload_id={upload_id}, group_id={group_id}")
        
        cognee_service = CogneeService()
        result = await cognee_service.delete_cognee_kg(group_id)
        
        if result.get("success"):
            return {
                "success": True,
                "upload_id": upload_id,
                "group_id": group_id,
                "results": result.get("results", {}),
                "message": "Cogneeå›¾è°±åˆ é™¤æˆåŠŸ"
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=f"åˆ é™¤å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤Cogneeå›¾è°±å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")


@router.post("/step2/cognee-build")
async def step2_cognee_build(
    request: Step2CogneeBuildRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤2: Cogneeç« èŠ‚çº§å¤„ç†
    
    æ„å»ºç« èŠ‚çº§çŸ¥è¯†å›¾è°±
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å·²åˆ†å—
        if not document.chunks_path:
            raise HTTPException(status_code=400, detail="æ–‡æ¡£å°šæœªåˆ†å—ï¼Œè¯·å…ˆå®Œæˆæ–‡æ¡£åˆ†å—")
        
        service = IntelligentChatService()
        result = await service.step2_cognee_build(
            upload_id=request.upload_id,
            group_id=request.group_id,  # å¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨ç”Ÿæˆ
            provider=request.provider,
            temperature=request.temperature,
            cognify_template_mode=request.cognify_template_mode,
            cognify_template_config_json=request.cognify_template_config_json,
            cognify_system_prompt=request.cognify_system_prompt,
            cognify_user_prompt_template=request.cognify_user_prompt_template,
            cognify_template_type=request.cognify_template_type,
            memify_template_mode=request.memify_template_mode,
            memify_template_config_json=request.memify_template_config_json,
            memify_system_prompt=request.memify_system_prompt,
            memify_user_prompt_template=request.memify_user_prompt_template,
            memify_template_type=request.memify_template_type,
            memify_rules=request.memify_rules
        )
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ­¥éª¤2æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.get("/linkage/check")
async def check_linkage(
    group_id: str = Query(..., description="æ–‡æ¡£ç»„ID"),
    upload_id: Optional[int] = Query(None, description="æ–‡æ¡£ä¸Šä¼ IDï¼ˆå¯é€‰ï¼Œç”¨äºéªŒè¯doc_idï¼‰")
):
    """
    æ£€æŸ¥ Graphiti å’Œ Cognee çš„å…³è”çŠ¶æ€
    
    éªŒè¯ï¼š
    1. Graphiti Episode æ˜¯å¦å­˜åœ¨
    2. Cognee TextDocument æ˜¯å¦å­˜åœ¨
    3. ä¸¤è€…ä¹‹é—´çš„å…³è”å…³ç³»æ˜¯å¦å»ºç«‹
    4. doc_idã€group_idã€version æ˜¯å¦ä¸€è‡´
    """
    try:
        from app.core.neo4j_client import neo4j_client
        from app.core.mysql_client import SessionLocal
        from app.models.document_upload import DocumentUpload
        from app.services.word_document_service import WordDocumentService
        
        result = {
            "group_id": group_id,
            "graphiti": {
                "exists": False,
                "episode_uuid": None,
                "episode_id": None,
                "doc_id": None,
                "version": None
            },
            "cognee": {
                "exists": False,
                "text_document_uuid": None,
                "dataset_name": None
            },
            "linkage": {
                "established": False,
                "relation_type": None,
                "doc_id_match": False,
                "group_id_match": False,
                "version_match": False
            }
        }
        
        # 1. æŸ¥æ‰¾ Graphiti Episode
        find_episode_query = """
        MATCH (e:Episodic)
        WHERE e.group_id = $group_id
        RETURN e.uuid as episode_uuid, e.episode_id as episode_id, 
               e.doc_id as doc_id, e.version as version
        ORDER BY e.created_at DESC
        LIMIT 1
        """
        
        episode_results = neo4j_client.execute_query(find_episode_query, {
            "group_id": group_id
        })
        
        if episode_results and len(episode_results) > 0:
            episode_data = episode_results[0]
            result["graphiti"]["exists"] = True
            result["graphiti"]["episode_uuid"] = episode_data.get("episode_uuid")
            result["graphiti"]["episode_id"] = episode_data.get("episode_id")
            result["graphiti"]["doc_id"] = episode_data.get("doc_id")
            result["graphiti"]["version"] = episode_data.get("version")
        
        # 2. æŸ¥æ‰¾ Cognee TextDocument
        find_text_document_query = """
        MATCH (td:TextDocument)
        WHERE '__Node__' IN labels(td)
          AND 'TextDocument' IN labels(td)
        RETURN td.id as text_document_uuid, td.name as dataset_name
        ORDER BY td.created_at DESC
        LIMIT 1
        """
        
        text_doc_results = neo4j_client.execute_query(find_text_document_query)
        
        if text_doc_results and len(text_doc_results) > 0:
            text_doc_data = text_doc_results[0]
            result["cognee"]["exists"] = True
            result["cognee"]["text_document_uuid"] = text_doc_data.get("text_document_uuid")
            result["cognee"]["dataset_name"] = text_doc_data.get("dataset_name")
        
        # 3. æ£€æŸ¥å…³è”å…³ç³»
        if result["graphiti"]["exists"] and result["cognee"]["exists"]:
            check_linkage_query = """
            MATCH (td:TextDocument {id: $text_doc_uuid})-[r]->(e:Episodic {uuid: $episode_uuid})
            RETURN type(r) as relation_type, id(r) as relation_id
            LIMIT 1
            """
            
            linkage_results = neo4j_client.execute_query(check_linkage_query, {
                "text_doc_uuid": result["cognee"]["text_document_uuid"],
                "episode_uuid": result["graphiti"]["episode_uuid"]
            })
            
            if linkage_results and len(linkage_results) > 0:
                result["linkage"]["established"] = True
                result["linkage"]["relation_type"] = linkage_results[0].get("relation_type")
            
            # 4. éªŒè¯ä¸€è‡´æ€§
            if upload_id:
                db = SessionLocal()
                try:
                    document = db.query(DocumentUpload).filter(DocumentUpload.id == upload_id).first()
                    if document:
                        doc_id = f"DOC_{upload_id}"
                        base_name = WordDocumentService._extract_base_name(document.file_name)
                        version, version_number = WordDocumentService._extract_version(document.file_name)
                        doc_version = version or "v1.0"
                        
                        result["linkage"]["doc_id_match"] = (result["graphiti"]["doc_id"] == doc_id)
                        result["linkage"]["group_id_match"] = True  # group_id å·²åŒ¹é…ï¼ˆé€šè¿‡æŸ¥è¯¢æ¡ä»¶ï¼‰
                        result["linkage"]["version_match"] = (result["graphiti"]["version"] == doc_version)
                finally:
                    db.close()
        
        return result
        
    except Exception as e:
        logger.error(f"æ£€æŸ¥å…³è”çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥å¤±è´¥: {str(e)}")


@router.get("/step2/cognee-graph")
async def get_cognee_graph(
    group_id: str = Query(..., description="æ–‡æ¡£ç»„ID"),
    limit: int = Query(500, ge=1, le=2000, description="è¿”å›èŠ‚ç‚¹æ•°é‡é™åˆ¶")
):
    """
    è·å–Cogneeå›¾è°±æ•°æ®
    
    æŸ¥è¯¢æŒ‡å®šgroup_idçš„CogneeèŠ‚ç‚¹å’Œå…³ç³»
    """
    try:
        from app.core.neo4j_client import neo4j_client
        from app.core.utils import serialize_neo4j_properties
        
        # æ³¨æ„ï¼šCognee åˆ›å»ºçš„èŠ‚ç‚¹æ²¡æœ‰ group_idã€dataset_name æˆ– dataset_id å±æ€§
        # æ‰€ä»¥ç›´æ¥æŸ¥è¯¢æ‰€æœ‰ Cognee èŠ‚ç‚¹ï¼ˆé€šè¿‡æ ‡ç­¾è¯†åˆ«ï¼‰
        # å¦‚æœ Neo4j ä¸­æœ‰å¤šä¸ª group_id çš„èŠ‚ç‚¹ï¼Œå¯èƒ½éœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼åŒºåˆ†
        query = """
        // æŸ¥è¯¢æ‰€æœ‰ Cognee èŠ‚ç‚¹ï¼ˆCognee èŠ‚ç‚¹æ²¡æœ‰ group_id å±æ€§ï¼Œåªèƒ½é€šè¿‡æ ‡ç­¾æŸ¥è¯¢ï¼‰
        MATCH (n)
        WHERE '__Node__' IN labels(n)
           AND ('Entity' IN labels(n)
           OR 'DocumentChunk' IN labels(n)
           OR 'TextDocument' IN labels(n)
           OR 'EntityType' IN labels(n)
           OR 'TextSummary' IN labels(n)
           OR 'KnowledgeNode' IN labels(n))
        WITH collect(DISTINCT n)[0..$limit] as nodes
        
        // æŸ¥è¯¢è¿™äº›èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»
        MATCH (a)-[r]->(b)
        WHERE a IN nodes AND b IN nodes
        
        WITH nodes, collect(DISTINCT r)[0..$limit] as relations
        
        RETURN 
          [node IN nodes | {
            id: id(node),
            labels: labels(node),
            properties: properties(node)
          }] as nodes,
          [rel IN relations | {
            id: id(rel),
            source: id(startNode(rel)),
            target: id(endNode(rel)),
            type: type(rel),
            properties: properties(rel)
          }] as edges
        """
        
        result = neo4j_client.execute_query(query, {
            "group_id": group_id,
            "limit": limit
        })
        
        if not result:
            return {"nodes": [], "edges": []}
        
        data = result[0]
        
        # å¤„ç†èŠ‚ç‚¹
        nodes_dict = {}
        for node_data in data.get("nodes", []):
            if node_data.get("id") is not None:
                node_id = str(node_data["id"])
                props = node_data.get("properties", {})
                nodes_dict[node_id] = {
                    "id": node_id,
                    "labels": node_data.get("labels", []),
                    "name": props.get("name", ""),
                    "type": node_data.get("labels", ["Node"])[0] if node_data.get("labels") else "Node",
                    "properties": serialize_neo4j_properties(props)
                }
        
        # å¤„ç†è¾¹
        edges = []
        for edge_data in data.get("edges", []):
            if edge_data.get("id") is not None and edge_data.get("source") is not None:
                source_id = str(edge_data["source"])
                target_id = str(edge_data["target"])
                # ç¡®ä¿sourceå’ŒtargetèŠ‚ç‚¹éƒ½å­˜åœ¨
                if source_id in nodes_dict and target_id in nodes_dict:
                    edges.append({
                        "id": str(edge_data["id"]),
                        "source": source_id,
                        "target": target_id,
                        "type": edge_data.get("type", ""),
                        "properties": serialize_neo4j_properties(edge_data.get("properties", {}))
                    })
        
        return {
            "nodes": list(nodes_dict.values()),
            "edges": edges,
            "group_id": group_id
        }
        
    except Exception as e:
        logger.error(f"è·å–Cogneeå›¾è°±æ•°æ®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/step3/milvus-vectorize")
async def step3_milvus_vectorize(
    request: Step3MilvusVectorizeRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤3: Milvuså‘é‡åŒ–å¤„ç†
    
    ç”Ÿæˆæ–‡æ¡£æ‘˜è¦ã€Requirementã€æµç¨‹/è§„åˆ™å‘é‡å¹¶å­˜å‚¨åˆ°Milvus
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # éªŒè¯æ–‡æ¡£å­˜åœ¨
        document = db.query(DocumentUpload).filter(DocumentUpload.id == request.upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={request.upload_id}")
        
        service = IntelligentChatService()
        result = await service.step3_milvus_vectorize(
            upload_id=request.upload_id,
            group_id=request.group_id
        )
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ­¥éª¤3æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


# ==================== æ£€ç´¢ç”Ÿæˆæµç¨‹ API ====================

@router.post("/step4/milvus-recall")
async def step4_milvus_recall(
    request: Step4MilvusRecallRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤4: Milvuså¿«é€Ÿå¬å›
    
    å‘é‡ç›¸ä¼¼æ€§æ£€ç´¢ï¼Œè¿”å›Top Kç›¸ä¼¼ç»“æœ
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.step4_milvus_recall(
            query=request.query,
            top_k=request.top_k,
            group_ids=request.group_ids
        )
        
        return result
        
    except Exception as e:
        logger.error(f"æ­¥éª¤4æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/step5/neo4j-refine")
async def step5_neo4j_refine(
    request: Step5Neo4jRefineRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤5: Neo4jç²¾ç­›
    
    ä½¿ç”¨Graphitiå’ŒCogneeè”åˆæŸ¥è¯¢ï¼Œç²¾ç­›Milvuså¬å›ç»“æœ
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.step5_neo4j_refine(
            query=request.query,
            recall_results=request.recall_results
        )
        
        return result
        
    except Exception as e:
        logger.error(f"æ­¥éª¤5æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/step6/mem0-inject")
async def step6_mem0_inject(
    request: Step6Mem0InjectRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤6: Mem0è®°å¿†æ³¨å…¥
    
    æ£€ç´¢ç”¨æˆ·åå¥½ã€ä¼šè¯ä¸Šä¸‹æ–‡ã€åé¦ˆè®°å¿†ï¼Œæ³¨å…¥åˆ°æ£€ç´¢ç»“æœ
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # è·å–ç”¨æˆ·ID
        user_id = str(current_user.id) if current_user else request.user_id or "anonymous"
        
        service = IntelligentChatService()
        result = await service.step6_mem0_inject(
            query=request.query,
            refined_results=request.refined_results,
            user_id=user_id,
            session_id=request.session_id
        )
        
        return result
        
    except Exception as e:
        logger.error(f"æ­¥éª¤6æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/mem0-chat")
async def mem0_chat(
    request: Mem0ChatRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    Mem0 ç‹¬ç«‹é—®ç­”æ¥å£
    
    ç”¨äºéªŒè¯ Mem0 çš„ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ï¼š
    - æ£€ç´¢ Mem0 è®°å¿†
    - ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”ï¼ˆç»“åˆè®°å¿†å’Œå¯¹è¯å†å²ï¼‰
    - ä¿å­˜å¯¹è¯åˆ° Mem0
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        # è·å–ç”¨æˆ·ID
        user_id = str(current_user.id) if current_user else request.user_id or "anonymous"
        
        service = IntelligentChatService()
        result = await service.mem0_chat(
            query=request.query,
            user_id=user_id,
            session_id=request.session_id,
            conversation_history=request.conversation_history,
            provider=request.provider,
            temperature=request.temperature
        )
        
        return result
        
    except Exception as e:
        logger.error(f"Mem0 é—®ç­”å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/step7/llm-generate")
async def step7_llm_generate(
    request: Step7LLMGenerateRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤7: LLMç”Ÿæˆ
    
    ç”Ÿæˆæ–°éœ€æ±‚æ–‡æ¡£ã€å¯¹æ¯”åˆ†æã€å¤ç”¨å»ºè®®ã€é£é™©æç¤º
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.step7_llm_generate(
            query=request.query,
            retrieval_results=request.retrieval_results or [],
            provider=request.provider,
            temperature=request.temperature
        )
        
        return result
        
    except Exception as e:
        logger.error(f"æ­¥éª¤7æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/step7/llm-generate-stream")
async def step7_llm_generate_stream(
    request: Step7LLMGenerateRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ­¥éª¤7: LLMæµå¼ç”Ÿæˆï¼ˆä»…ä¸»è¦å›ç­”ï¼‰
    
    ä½¿ç”¨Server-Sent Events (SSE)æµå¼è¿”å›ç”Ÿæˆçš„å›ç­”
    æ”¯æŒ qianwenã€deepseekã€kimi
    """
    try:
        logger.info(f"æ”¶åˆ°æµå¼ç”Ÿæˆè¯·æ±‚: query={request.query[:50]}..., provider={request.provider}, retrieval_resultsæ•°é‡={len(request.retrieval_results or [])}")
        from app.services.intelligent_chat_service import IntelligentChatService
        
        if request.provider not in ["qianwen", "deepseek", "kimi"]:
            raise HTTPException(
                status_code=400, 
                detail=f"æµå¼è¾“å‡ºä»…æ”¯æŒ qianwenã€deepseekã€kimiï¼Œå½“å‰provider: {request.provider}"
            )
        
        service = IntelligentChatService()
        
        async def generate():
            """ç”ŸæˆSSEæ ¼å¼çš„æµå¼å“åº”"""
            try:
                import time
                stream_start_time = time.time()
                statistics = None
                
                async for chunk in service.step7_llm_generate_stream(
                    query=request.query,
                    retrieval_results=request.retrieval_results or [],
                    provider=request.provider,
                    temperature=request.temperature
                ):
                    # æ£€æŸ¥chunkæ˜¯å¦æ˜¯ç»Ÿè®¡ä¿¡æ¯ï¼ˆdictç±»å‹ä¸”åŒ…å«__statistics__å­—æ®µï¼‰
                    if isinstance(chunk, dict) and '__statistics__' in chunk:
                        statistics = chunk['__statistics__']
                    else:
                        # æ™®é€šæ–‡æœ¬chunkï¼ŒSSEæ ¼å¼: data: {json}\n\n
                        yield f"data: {json.dumps({'content': chunk, 'done': False})}\n\n"
                
                # æµå¼ç”Ÿæˆå®Œæˆåï¼Œå‘é€ç»Ÿè®¡ä¿¡æ¯
                if statistics:
                    yield f"data: {json.dumps({'statistics': statistics, 'done': False})}\n\n"
                else:
                    # å¦‚æœæ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼Œè®¡ç®—è€—æ—¶ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                    main_answer_time = time.time() - stream_start_time
                    yield f"data: {json.dumps({'statistics': {'main_answer_time': round(main_answer_time, 2), 'temperature': request.temperature}, 'done': False})}\n\n"
                
                # å‘é€å®Œæˆä¿¡å·
                yield f"data: {json.dumps({'content': '', 'done': True})}\n\n"
            except Exception as e:
                logger.error(f"æµå¼ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
                # å‘é€é”™è¯¯ä¿¡æ¯
                yield f"data: {json.dumps({'error': str(e), 'done': True})}\n\n"
        
        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"  # ç¦ç”¨Nginxç¼“å†²
            }
        )
        
    except HTTPException:
        raise
    except ValueError as e:
        logger.error(f"æ­¥éª¤7æµå¼ç”Ÿæˆå‚æ•°é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=f"å‚æ•°é”™è¯¯: {str(e)}")
    except Exception as e:
        logger.error(f"æ­¥éª¤7æµå¼ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


# ==================== æ™ºèƒ½æ£€ç´¢ API ====================

@router.post("/smart-retrieval")
async def smart_retrieval(
    request: SmartRetrievalRequest,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    æ™ºèƒ½æ£€ç´¢ï¼šä¸¤é˜¶æ®µæ£€ç´¢ç­–ç•¥
    
    é˜¶æ®µ1ï¼šMilvuså¿«é€Ÿå¬å›ï¼ˆæ–‡æ¡£çº§åˆ«ï¼‰
    - åªä½¿ç”¨Documentç›¸å…³çš„å››ä¸ªå‘é‡ç±»å‹
    - æŒ‰æ–‡æ¡£èšåˆç»“æœ
    - é€‰æ‹©Top3æ–‡æ¡£
    
    é˜¶æ®µ2ï¼šç²¾ç»†å¤„ç†ï¼ˆæ–‡æ¡£çº§åˆ«ï¼‰
    - å¯¹Top3æ–‡æ¡£ï¼Œä½¿ç”¨Graphitiå’ŒCogneeçŸ¥è¯†å›¾è°±
    - ä½¿ç”¨Milvuså’ŒNeo4jè¿›è¡Œæ·±åº¦æ£€ç´¢
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.smart_retrieval(
            query=request.query,
            top_k=request.top_k,
            min_score=request.min_score,
            group_ids=request.group_ids,
            enable_refine=request.enable_refine
        )
        
        return result
        
    except Exception as e:
        logger.error(f"æ™ºèƒ½æ£€ç´¢æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


# ==================== æ–‡æ¡£å±‚çº§æŸ¥è¯¢ API ====================

@router.get("/document-hierarchy/{upload_id}")
async def get_document_hierarchy(
    upload_id: int,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    è·å–æ–‡æ¡£çš„å®Œæ•´å±‚çº§ç»“æ„
    
    è¿”å›æ–‡æ¡£çº§åˆ«ã€ç« èŠ‚çº§åˆ«ã€åˆ†å—çº§åˆ«çš„æ‰€æœ‰èŠ‚ç‚¹å’Œå±æ€§ä¿¡æ¯
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.get_document_hierarchy(upload_id=upload_id)
        
        return result
        
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ–‡æ¡£å±‚çº§ç»“æ„å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/chunks-cognee-mapping/{upload_id}")
async def get_chunks_cognee_mapping(
    upload_id: int,
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    è·å–chunksä¸CogneeèŠ‚ç‚¹çš„æ˜ å°„å…³ç³»
    
    è¿”å›æ¯ä¸ªchunkå¯¹åº”çš„TextDocument/DataNodeå’ŒDocumentChunkä¿¡æ¯
    """
    try:
        from app.services.intelligent_chat_service import IntelligentChatService
        
        service = IntelligentChatService()
        result = await service.get_chunks_cognee_mapping(upload_id=upload_id)
        
        return result
        
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"æŸ¥è¯¢chunks-Cogneeæ˜ å°„å…³ç³»å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.delete("/graphiti-graph/{upload_id}", response_model=Dict[str, Any])
async def delete_graphiti_graph(
    upload_id: int,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user_optional)
):
    """
    åˆ é™¤æ–‡æ¡£çš„Graphitiå›¾è°±æ•°æ®
    
    åˆ é™¤åŒ…æ‹¬ï¼š
    1. Neo4jä¸­çš„Entityã€Edgeã€Episodeã€CommunityèŠ‚ç‚¹å’Œå…³ç³»
    2. Milvusä¸­çš„å‘é‡æ•°æ®ï¼ˆEpisodeã€Entityã€Edgeã€Communityå‘é‡ï¼‰
    3. MySQLä¸­çš„æ¨¡æ¿é…ç½®è®°å½•ï¼ˆEntityEdgeTemplateï¼‰
    4. æ¸…ç©ºDocumentUploadä¸­çš„document_idå­—æ®µï¼ˆä¿ç•™è®°å½•ï¼‰
    """
    try:
        from app.core.neo4j_client import neo4j_client
        from app.services.milvus_service import MilvusService, VectorType
        from app.models.template import EntityEdgeTemplate
        
        # 1. è·å–æ–‡æ¡£ä¿¡æ¯
        document = db.query(DocumentUpload).filter(DocumentUpload.id == upload_id).first()
        if not document:
            raise HTTPException(status_code=404, detail=f"æ–‡æ¡£ä¸å­˜åœ¨: upload_id={upload_id}")
        
        group_id = document.document_id
        if not group_id:
            raise HTTPException(status_code=400, detail=f"æ–‡æ¡£æœªå¤„ç†ï¼Œæ²¡æœ‰group_id: upload_id={upload_id}")
        
        logger.info(f"å¼€å§‹åˆ é™¤Graphitiå›¾è°±: upload_id={upload_id}, group_id={group_id}")
        
        deletion_results = {
            "neo4j": {"success": False, "details": {}},
            "milvus": {"success": False, "details": {}},
            "mysql_template": {"success": False, "details": {}},
            "mysql_document": {"success": False, "details": {}}
        }
        
        # 2. åˆ é™¤Neo4jä¸­çš„å›¾è°±æ•°æ®
        try:
            # 2.1 ç»Ÿè®¡è¦åˆ é™¤çš„æ•°æ®
            stats_query = """
            MATCH (e:Episodic)
            WHERE e.group_id = $group_id
            WITH collect(e.uuid) as episode_uuids
            
            MATCH (n:Entity)
            WHERE n.group_id = $group_id
            
            MATCH ()-[r:RELATES_TO|MENTIONS|CONTAINS|HAS_MEMBER]->()
            WHERE r.group_id = $group_id OR (size(episode_uuids) > 0 AND r.episode_uuid IN episode_uuids)
            
            RETURN 
              size(episode_uuids) as episode_count,
              count(DISTINCT n) as entity_count,
              count(DISTINCT r) as relationship_count
            """
            
            stats_result = neo4j_client.execute_query(stats_query, {"group_id": group_id})
            stats = stats_result[0] if stats_result else {}
            episode_count = stats.get("episode_count", 0)
            entity_count = stats.get("entity_count", 0)
            relationship_count = stats.get("relationship_count", 0)
            
            # 2.2 åˆ é™¤æ‰€æœ‰ç›¸å…³çš„å…³ç³»ï¼ˆå…ˆåˆ é™¤å…³ç³»ï¼Œé¿å…çº¦æŸé—®é¢˜ï¼‰
            delete_relationships_query = """
            MATCH (e:Episodic)
            WHERE e.group_id = $group_id
            WITH collect(e.uuid) as episode_uuids
            
            MATCH ()-[r:RELATES_TO|MENTIONS|CONTAINS|HAS_MEMBER]->()
            WHERE r.group_id = $group_id OR (size(episode_uuids) > 0 AND r.episode_uuid IN episode_uuids)
            DELETE r
            RETURN count(r) as deleted_count
            """
            
            neo4j_client.execute_write(delete_relationships_query, {"group_id": group_id})
            logger.info(f"å·²åˆ é™¤ {relationship_count} ä¸ªå…³ç³»")
            
            # 2.3 åˆ é™¤æ‰€æœ‰ç›¸å…³çš„EntityèŠ‚ç‚¹
            delete_entities_query = """
            MATCH (n:Entity)
            WHERE n.group_id = $group_id
            DETACH DELETE n
            RETURN count(n) as deleted_count
            """
            
            neo4j_client.execute_write(delete_entities_query, {"group_id": group_id})
            logger.info(f"å·²åˆ é™¤ {entity_count} ä¸ªå®ä½“")
            
            # 2.4 åˆ é™¤æ‰€æœ‰ç›¸å…³çš„EpisodeèŠ‚ç‚¹
            delete_episodes_query = """
            MATCH (e:Episodic)
            WHERE e.group_id = $group_id
            DETACH DELETE e
            RETURN count(e) as deleted_count
            """
            
            neo4j_client.execute_write(delete_episodes_query, {"group_id": group_id})
            logger.info(f"å·²åˆ é™¤ {episode_count} ä¸ªEpisode")
            
            # 2.5 åˆ é™¤æ‰€æœ‰ç›¸å…³çš„CommunityèŠ‚ç‚¹
            count_communities_query = """
            MATCH (c:Community)
            WHERE (c.group_id = $group_id OR 
                   (c.group_id IS NOT NULL AND 
                    (toString(c.group_id) CONTAINS $group_id OR 
                     $group_id IN c.group_id)))
            RETURN count(c) as deleted_count
            """
            count_result = neo4j_client.execute_query(count_communities_query, {"group_id": group_id})
            deleted_communities = count_result[0].get("deleted_count", 0) if count_result else 0
            
            delete_communities_query = """
            MATCH (c:Community)
            WHERE (c.group_id = $group_id OR 
                   (c.group_id IS NOT NULL AND 
                    (toString(c.group_id) CONTAINS $group_id OR 
                     $group_id IN c.group_id)))
            DETACH DELETE c
            """
            neo4j_client.execute_write(delete_communities_query, {"group_id": group_id})
            logger.info(f"å·²åˆ é™¤ {deleted_communities} ä¸ªCommunity")
            
            deletion_results["neo4j"] = {
                "success": True,
                "details": {
                    "episode_count": episode_count,
                    "entity_count": entity_count,
                    "relationship_count": relationship_count,
                    "community_count": deleted_communities
                }
            }
        except Exception as e:
            logger.error(f"åˆ é™¤Neo4jå›¾è°±æ•°æ®å¤±è´¥: {e}", exc_info=True)
            deletion_results["neo4j"] = {
                "success": False,
                "error": str(e)
            }
        
        # 3. åˆ é™¤Milvusä¸­çš„å‘é‡æ•°æ®
        try:
            milvus_service = MilvusService()
            deleted_vectors = {}
            vector_errors = {}
            
            for vector_type in VectorType:
                try:
                    if milvus_service.delete_by_group_id(vector_type, group_id):
                        deleted_vectors[vector_type.value] = True
                    else:
                        deleted_vectors[vector_type.value] = False
                        vector_errors[vector_type.value] = "åˆ é™¤è¿”å›Falseï¼ˆå¯èƒ½collectionæœªåŠ è½½æˆ–æ•°æ®ä¸å­˜åœ¨ï¼‰"
                except Exception as e:
                    deleted_vectors[vector_type.value] = False
                    vector_errors[vector_type.value] = str(e)
                    logger.error(f"åˆ é™¤ {vector_type.value} å‘é‡å¤±è´¥: {e}", exc_info=True)
            
            deletion_results["milvus"] = {
                "success": all(deleted_vectors.values()),
                "details": deleted_vectors,
                "errors": vector_errors if vector_errors else None
            }
            logger.info(f"å·²åˆ é™¤Milvuså‘é‡: {deleted_vectors}")
            if vector_errors:
                logger.warning(f"Milvuså‘é‡åˆ é™¤éƒ¨åˆ†å¤±è´¥: {vector_errors}")
        except Exception as e:
            logger.error(f"åˆ é™¤Milvuså‘é‡å¤±è´¥: {e}", exc_info=True)
            deletion_results["milvus"] = {
                "success": False,
                "error": str(e)
            }
        
        # 4. åˆ é™¤MySQLä¸­çš„æ¨¡æ¿é…ç½®è®°å½•
        try:
            templates = db.query(EntityEdgeTemplate).filter(
                EntityEdgeTemplate.source_document_id == upload_id,
                EntityEdgeTemplate.analysis_mode == "graphiti_document"
            ).all()
            
            template_count = len(templates)
            for template in templates:
                db.delete(template)
            
            db.commit()
            logger.info(f"å·²åˆ é™¤ {template_count} ä¸ªæ¨¡æ¿é…ç½®è®°å½•")
            
            deletion_results["mysql_template"] = {
                "success": True,
                "details": {"deleted_count": template_count}
            }
        except Exception as e:
            db.rollback()
            logger.error(f"åˆ é™¤MySQLæ¨¡æ¿é…ç½®è®°å½•å¤±è´¥: {e}", exc_info=True)
            deletion_results["mysql_template"] = {
                "success": False,
                "error": str(e)
            }
        
        # 5. æ¸…ç©ºDocumentUploadä¸­çš„document_idå­—æ®µï¼ˆä¿ç•™è®°å½•ï¼‰
        try:
            document.document_id = None
            db.commit()
            logger.info(f"å·²æ¸…ç©ºæ–‡æ¡£çš„document_idå­—æ®µ")
            
            deletion_results["mysql_document"] = {
                "success": True,
                "details": {"cleared": True}
            }
        except Exception as e:
            db.rollback()
            logger.error(f"æ¸…ç©ºæ–‡æ¡£document_idå­—æ®µå¤±è´¥: {e}", exc_info=True)
            deletion_results["mysql_document"] = {
                "success": False,
                "error": str(e)
            }
        
        # 6. æ±‡æ€»ç»“æœ
        all_success = all([
            deletion_results["neo4j"]["success"],
            deletion_results["milvus"]["success"],
            deletion_results["mysql_template"]["success"],
            deletion_results["mysql_document"]["success"]
        ])
        
        if all_success:
            logger.info(f"Graphitiå›¾è°±åˆ é™¤æˆåŠŸ: upload_id={upload_id}, group_id={group_id}")
            return {
                "success": True,
                "message": "å›¾è°±åˆ é™¤æˆåŠŸ",
                "upload_id": upload_id,
                "group_id": group_id,
                "deletion_results": deletion_results
            }
        else:
            # éƒ¨åˆ†æˆåŠŸï¼Œè¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯
            errors = []
            for key, result in deletion_results.items():
                if not result["success"]:
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    # å¦‚æœæ˜¯Milvusé”™è¯¯ï¼Œå°è¯•è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    if key == "milvus" and result.get("errors"):
                        error_details = []
                        for vec_type, vec_error in result["errors"].items():
                            error_details.append(f"{vec_type}: {vec_error}")
                        if error_details:
                            error_msg = "; ".join(error_details)
                    errors.append(f"{key}: {error_msg}")
            
            logger.warning(f"Graphitiå›¾è°±åˆ é™¤éƒ¨åˆ†æˆåŠŸ: upload_id={upload_id}, errors={errors}")
            return {
                "success": False,
                "message": f"å›¾è°±åˆ é™¤éƒ¨åˆ†æˆåŠŸï¼Œéƒ¨åˆ†å¤±è´¥: {', '.join(errors)}",
                "upload_id": upload_id,
                "group_id": group_id,
                "deletion_results": deletion_results
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤Graphitiå›¾è°±å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

