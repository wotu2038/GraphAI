"""
Monkey patch for add_rule_associations to use simple BaseModel instead of DataPoint

è¿™ä¸ª patch è§£å†³äº† Cognee çš„ DataPoint ç±»å¯¼è‡´ LLM è°ƒç”¨è¶…æ—¶çš„é—®é¢˜ã€‚
é€šè¿‡ä½¿ç”¨ç®€å•çš„ Pydantic BaseModel è¿›è¡Œ LLM è°ƒç”¨ï¼Œç„¶åè½¬æ¢ä¸º DataPoint æ ¼å¼ä¿å­˜ã€‚

æ€§èƒ½å¯¹æ¯”ï¼š
- ç®€å• BaseModelï¼š6.17 ç§’ âœ…
- Cognee DataPointï¼š212.23 ç§’ âŒ (Server disconnected)
"""

import logging
from typing import List, Optional
from uuid import NAMESPACE_OID, uuid5
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# ç®€å•çš„ Pydantic æ¨¡å‹ï¼Œç”¨äº LLM è°ƒç”¨
# æ³¨æ„ï¼šä¸ºäº†é¿å… Instructor çš„ JSON Schema $ref é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨å†…è”å®šä¹‰è€Œä¸æ˜¯åµŒå¥—æ¨¡å‹
class SimpleRuleSet(BaseModel):
    """ç®€å•çš„è§„åˆ™é›†åˆï¼Œç”¨äº LLM ç»“æ„åŒ–è¾“å‡º"""
    rules: List[str] = Field(
        ...,
        description="List of developer rules extracted from the input text. Each rule is a string representing a coding best practice or guideline.",
    )


async def patched_add_rule_associations(
    data: str,
    rules_nodeset_name: str = "default_rules",  # æ·»åŠ é»˜è®¤å€¼
    user_prompt_location: str = "coding_rule_association_agent_user.txt",
    system_prompt_location: str = "coding_rule_association_agent_system.txt",
    user_prompt: Optional[str] = None,  # ç›´æ¥ä¼ å…¥çš„User Promptå†…å®¹ï¼ˆä¼˜å…ˆçº§é«˜äºuser_prompt_locationï¼‰
    system_prompt: Optional[str] = None,  # ç›´æ¥ä¼ å…¥çš„System Promptå†…å®¹ï¼ˆä¼˜å…ˆçº§é«˜äºsystem_prompt_locationï¼‰
    **kwargs  # æ¥å—é¢å¤–çš„å‚æ•°ï¼ˆPipeline å¯èƒ½ä¼ é€’ï¼‰
):
    """
    ä¿®å¤ç‰ˆçš„ add_rule_associationsï¼Œä½¿ç”¨ç®€å•çš„ BaseModel è¿›è¡Œ LLM è°ƒç”¨
    
    å…³é”®ä¿®æ”¹ï¼š
    1. ä½¿ç”¨ SimpleRuleSet ä»£æ›¿ Cognee çš„ RuleSetï¼ˆç»§æ‰¿è‡ª DataPointï¼‰è¿›è¡Œ LLM è°ƒç”¨
    2. LLM è°ƒç”¨æˆåŠŸåï¼Œå°†ç»“æœè½¬æ¢ä¸º Cognee çš„ Ruleï¼ˆDataPointï¼‰æ ¼å¼
    3. æ€§èƒ½æå‡ï¼šä» 212 ç§’ï¼ˆå¤±è´¥ï¼‰é™ä½åˆ° 6 ç§’ï¼ˆæˆåŠŸï¼‰
    """
    from cognee.infrastructure.databases.graph import get_graph_engine
    from cognee.infrastructure.databases.vector import get_vector_engine
    from cognee.infrastructure.llm.prompts import render_prompt
    from cognee.infrastructure.llm import LLMGateway
    from cognee.modules.engine.models import NodeSet
    from cognee.tasks.storage import add_data_points, index_graph_edges
    
    # å¯¼å…¥ Cognee çš„åŸå§‹ Rule ç±»ï¼ˆç”¨äºæœ€ç»ˆä¿å­˜ï¼‰
    from cognee.tasks.codingagents.coding_rule_associations import Rule, get_existing_rules, get_origin_edges
    
    logger.info("ğŸ”§ ä½¿ç”¨ patched_add_rule_associationsï¼ˆä½¿ç”¨ç®€å• BaseModelï¼‰")
    
    if isinstance(data, list):
        data = " ".join(data)
    
    # æ­¥éª¤1: è·å–ç°æœ‰è§„åˆ™
    graph_engine = await get_graph_engine()
    existing_rules = await get_existing_rules(rules_nodeset_name=rules_nodeset_name)
    existing_rules_str = "\n".join(f"- {rule}" for rule in existing_rules)
    
    # æ­¥éª¤2: æ„å»º prompt
    # å¦‚æœç›´æ¥ä¼ å…¥äº†æç¤ºè¯å†…å®¹ï¼Œä½¿ç”¨ç›´æ¥ä¼ å…¥çš„å†…å®¹ï¼›å¦åˆ™ä½¿ç”¨æ–‡ä»¶è·¯å¾„åŠ è½½
    if user_prompt is not None:
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„user_promptï¼Œæ›¿æ¢å ä½ç¬¦
        final_user_prompt = user_prompt.replace("{chat}", data)
        final_user_prompt = final_user_prompt.replace("{rules}", existing_rules_str)
        # æ”¯æŒå…¶ä»–å ä½ç¬¦ï¼ˆå¦‚ {document_name}, {section_title}, {section_content} ç­‰ï¼‰
        # è¿™äº›å ä½ç¬¦åœ¨è°ƒç”¨æ—¶å·²ç»æ›¿æ¢ï¼Œè¿™é‡Œåªæ›¿æ¢ {chat} å’Œ {rules}
    else:
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„åŠ è½½
        user_context = {"chat": data, "rules": existing_rules_str}
        final_user_prompt = render_prompt(user_prompt_location, context=user_context)
    
    if system_prompt is not None:
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„system_prompt
        final_system_prompt = system_prompt
    else:
        # ä½¿ç”¨æ–‡ä»¶è·¯å¾„åŠ è½½
        final_system_prompt = render_prompt(system_prompt_location, context={})
    
    # æ­¥éª¤3: ä½¿ç”¨ç®€å•çš„ BaseModel è¿›è¡Œ LLM è°ƒç”¨ï¼ˆå…³é”®ä¿®å¤ï¼‰
    logger.info(f"  è°ƒç”¨ LLMï¼ˆä½¿ç”¨ SimpleRuleSetï¼‰...")
    simple_rule_list = await LLMGateway.acreate_structured_output(
        text_input=final_user_prompt,
        system_prompt=final_system_prompt,
        response_model=SimpleRuleSet  # â† ä½¿ç”¨ç®€å•çš„ BaseModel
    )
    logger.info(f"  âœ… LLM è°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(simple_rule_list.rules)} æ¡è§„åˆ™")
    
    # æ­¥éª¤4: è½¬æ¢ä¸º Cognee çš„ Ruleï¼ˆDataPointï¼‰æ ¼å¼
    rules_nodeset = NodeSet(
        id=uuid5(NAMESPACE_OID, name=rules_nodeset_name),
        name=rules_nodeset_name
    )
    
    cognee_rules = []
    for rule_text in simple_rule_list.rules:
        # åˆ›å»º Cognee çš„ Rule å¯¹è±¡ï¼ˆç°åœ¨ rules ç›´æ¥æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        cognee_rule = Rule(
            text=rule_text,
            belongs_to_set=rules_nodeset
        )
        cognee_rules.append(cognee_rule)
    
    # æ­¥éª¤5: è·å–å…³è”è¾¹
    edges_to_save = await get_origin_edges(data=data, rules=cognee_rules)
    
    # æ­¥éª¤6: ä¿å­˜åˆ°æ•°æ®åº“
    await add_data_points(data_points=cognee_rules)
    
    if len(edges_to_save) > 0:
        await graph_engine.add_edges(edges_to_save)
        await index_graph_edges(edges_to_save)
    
    logger.info(f"  âœ… å·²ä¿å­˜ {len(cognee_rules)} æ¡è§„åˆ™å’Œ {len(edges_to_save)} æ¡è¾¹")


def apply_patch():
    """åº”ç”¨ monkey patch"""
    try:
        import cognee.tasks.codingagents.coding_rule_associations as module
        original_func = module.add_rule_associations
        module.add_rule_associations = patched_add_rule_associations
        logger.info("âœ… å·²åº”ç”¨ add_rule_associations monkey patchï¼ˆä½¿ç”¨ç®€å• BaseModelï¼‰")
        return True
    except Exception as e:
        logger.error(f"âŒ æ— æ³•åº”ç”¨ add_rule_associations monkey patch: {e}")
        return False
